{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNkRQUdpS/uBViM9hreLLtf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ccwkWw7LmymJ","executionInfo":{"status":"ok","timestamp":1741521230389,"user_tz":-300,"elapsed":1202037,"user":{"displayName":"Eshan","userId":"01808735500782736716"}},"outputId":"d287a78f-deb6-495d-873e-5b8576f86af6"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","\u001b[1m2614/2614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 9ms/step - loss: 2.7553 - val_loss: 2.1565\n","Epoch 2/30\n","\u001b[1m2614/2614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 9ms/step - loss: 2.0669 - val_loss: 2.0055\n","Epoch 3/30\n","\u001b[1m2614/2614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 10ms/step - loss: 1.8982 - val_loss: 1.9242\n","Epoch 4/30\n","\u001b[1m2614/2614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 9ms/step - loss: 1.7972 - val_loss: 1.8814\n","Epoch 5/30\n","\u001b[1m2614/2614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - loss: 1.7232 - val_loss: 1.8344\n","Epoch 6/30\n","\u001b[1m2614/2614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - loss: 1.6716 - val_loss: 1.8029\n","Epoch 7/30\n","\u001b[1m2614/2614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - loss: 1.6339 - val_loss: 1.7790\n","Epoch 8/30\n","\u001b[1m2614/2614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - loss: 1.6030 - val_loss: 1.7617\n","Epoch 9/30\n","\u001b[1m2614/2614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - loss: 1.5685 - val_loss: 1.7486\n","Epoch 10/30\n","\u001b[1m2614/2614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 9ms/step - loss: 1.5463 - val_loss: 1.7396\n","Epoch 11/30\n","\u001b[1m2614/2614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 10ms/step - loss: 1.5262 - val_loss: 1.7204\n","Epoch 12/30\n","\u001b[1m2614/2614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 9ms/step - loss: 1.5017 - val_loss: 1.7266\n","Epoch 13/30\n","\u001b[1m2614/2614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - loss: 1.4873 - val_loss: 1.7166\n","Epoch 14/30\n","\u001b[1m2614/2614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - loss: 1.4772 - val_loss: 1.7119\n","Epoch 15/30\n","\u001b[1m2614/2614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 10ms/step - loss: 1.4586 - val_loss: 1.7085\n","Epoch 16/30\n","\u001b[1m2614/2614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 9ms/step - loss: 1.4464 - val_loss: 1.7105\n","Epoch 17/30\n","\u001b[1m2614/2614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 9ms/step - loss: 1.4395 - val_loss: 1.7053\n","Epoch 18/30\n","\u001b[1m2614/2614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - loss: 1.4260 - val_loss: 1.6962\n","Epoch 19/30\n","\u001b[1m2614/2614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - loss: 1.4167 - val_loss: 1.6956\n","Epoch 20/30\n","\u001b[1m2614/2614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - loss: 1.4077 - val_loss: 1.6925\n","Epoch 21/30\n","\u001b[1m2614/2614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 10ms/step - loss: 1.3972 - val_loss: 1.6870\n","Epoch 22/30\n","\u001b[1m2614/2614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 9ms/step - loss: 1.3901 - val_loss: 1.6984\n","Epoch 23/30\n","\u001b[1m2614/2614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 9ms/step - loss: 1.3820 - val_loss: 1.6850\n","Epoch 24/30\n","\u001b[1m2614/2614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - loss: 1.3743 - val_loss: 1.6946\n","Epoch 25/30\n","\u001b[1m2614/2614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 9ms/step - loss: 1.3671 - val_loss: 1.6947\n","Epoch 26/30\n","\u001b[1m2614/2614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - loss: 1.3594 - val_loss: 1.6980\n","Epoch 27/30\n","\u001b[1m2614/2614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - loss: 1.3518 - val_loss: 1.7007\n","Epoch 28/30\n","\u001b[1m2614/2614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 10ms/step - loss: 1.3489 - val_loss: 1.6998\n","Epoch 29/30\n","\u001b[1m2614/2614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 9ms/step - loss: 1.3428 - val_loss: 1.6978\n","Epoch 30/30\n","\u001b[1m2614/2614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 10ms/step - loss: 1.3380 - val_loss: 1.7042\n","\u001b[1m11618/11618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 3ms/step\n","Perplexity: 3.8840858936309814\n","ROMEO: eeyeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n"]}],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential  # Fix: Import Sequential\n","from tensorflow.keras.layers import LSTM, Dense\n","import urllib.request\n","from sklearn.model_selection import train_test_split\n","\n","# Download text data\n","url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n","urllib.request.urlretrieve(url, 'shakespeare.txt')\n","text = open('shakespeare.txt', 'r').read()\n","\n","# Create character mappings\n","chars = sorted(list(set(text)))\n","char_to_int = {ch:i for i, ch in enumerate(chars)}\n","int_to_char = {i:ch for i, ch in enumerate(chars)}\n","\n","# Prepare sequences\n","max_length = 100\n","step = 3\n","sentences = []\n","next_chars = []\n","\n","for i in range(0, len(text) - max_length, step):\n","    sentences.append(text[i:i + max_length])\n","    next_chars.append(text[i + max_length])\n","\n","# Vectorization\n","X = np.zeros((len(sentences), max_length, len(chars)), dtype=np.bool_)\n","y = np.zeros((len(sentences), len(chars)), dtype=np.bool_)\n","\n","for i, sentence in enumerate(sentences):\n","    for t, char in enumerate(sentence):\n","        X[i, t, char_to_int[char]] = 1\n","    y[i, char_to_int[next_chars[i]]] = 1\n","\n","# Build model\n","model = Sequential()\n","model.add(LSTM(128, input_shape=(max_length, len(chars))))\n","model.add(Dense(len(chars), activation='softmax'))\n","model.compile(loss='categorical_crossentropy', optimizer='adam')\n","\n","# Train model\n","history = model.fit(X, y, batch_size=128, epochs=30, validation_split=0.1)\n","\n","# Generate text\n","def generate_text(seed, length=400):\n","    generated = seed\n","    for _ in range(length):\n","        x_pred = np.zeros((1, max_length, len(chars)))\n","        for t, char in enumerate(seed):\n","            x_pred[0, t, char_to_int[char]] = 1\n","\n","        preds = model.predict(x_pred, verbose=0)[0]\n","        next_index = np.argmax(preds)\n","        next_char = int_to_char[next_index]\n","\n","        generated += next_char\n","        seed = seed[1:] + next_char\n","    return generated\n","\n","# Calculate perplexity\n","def calculate_perplexity(model, X, y):\n","    y_pred = model.predict(X)\n","    cross_entropy = tf.keras.losses.categorical_crossentropy(y, y_pred)\n","    perplexity = np.exp(np.mean(cross_entropy))\n","    return perplexity\n","\n","perplexity = calculate_perplexity(model, X, y)\n","print(f\"Perplexity: {perplexity}\")\n","\n","# Generate sample text\n","print(generate_text(\"ROMEO: \"))"]}]}